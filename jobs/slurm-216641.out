Train start time: 2024-08-23_11:33:36
Epoch progress:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch progress:   0%|          | 1/1000 [01:40<27:48:20, 100.20s/it]Epoch progress:   0%|          | 2/1000 [03:03<25:02:10, 90.31s/it] Epoch progress:   0%|          | 3/1000 [04:27<24:10:51, 87.31s/it]Epoch progress:   0%|          | 4/1000 [05:50<23:45:07, 85.85s/it]Epoch progress:   0%|          | 5/1000 [07:15<23:35:23, 85.35s/it]Epoch progress:   1%|          | 6/1000 [08:39<23:25:57, 84.87s/it]Epoch progress:   1%|          | 7/1000 [10:03<23:18:53, 84.53s/it]Epoch progress:   1%|          | 8/1000 [11:26<23:13:19, 84.27s/it]Epoch progress:   1%|          | 9/1000 [12:50<23:10:17, 84.17s/it]Epoch progress:   1%|          | 10/1000 [14:16<23:18:33, 84.76s/it]Epoch progress:   1%|          | 11/1000 [15:40<23:12:44, 84.49s/it]Epoch progress:   1%|          | 12/1000 [17:04<23:07:27, 84.26s/it]Epoch progress:   1%|▏         | 13/1000 [18:28<23:03:19, 84.09s/it]Epoch progress:   1%|▏         | 14/1000 [19:51<22:59:56, 83.97s/it]Epoch progress:   2%|▏         | 15/1000 [21:16<23:02:26, 84.21s/it]Epoch progress:   2%|▏         | 16/1000 [22:40<23:00:07, 84.15s/it]Epoch progress:   2%|▏         | 17/1000 [24:04<22:55:36, 83.96s/it]Epoch progress:   2%|▏         | 18/1000 [25:28<22:53:58, 83.95s/it]Epoch progress:   2%|▏         | 19/1000 [26:51<22:51:22, 83.88s/it]Epoch progress:   2%|▏         | 20/1000 [28:18<23:04:12, 84.75s/it]Epoch progress:   2%|▏         | 21/1000 [29:42<22:59:55, 84.57s/it]Epoch progress:   2%|▏         | 21/1000 [30:55<24:01:28, 88.34s/it]
Traceback (most recent call last):
  File "/users/PAS2490/marcusshen/cmame/imae/jobs/../program/main.py", line 39, in <module>
    main()
  File "/users/PAS2490/marcusshen/cmame/imae/jobs/../program/main.py", line 33, in main
    engine.evaluate_epoch(epoch)
  File "/users/PAS2490/marcusshen/cmame/imae/program/engines/irr_mae.py", line 91, in evaluate_epoch
    loss = loss_fn(output, chunk)
  File "/users/PAS2490/marcusshen/cmame/imae/program/utils/metrics.py", line 48, in forward
    ssim_values[:, i] = self.ssim_loss(output[:, i], chunk[:, i])
  File "/users/PAS2490/marcusshen/miniconda3/envs/imae/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/PAS2490/marcusshen/miniconda3/envs/imae/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/PAS2490/marcusshen/miniconda3/envs/imae/lib/python3.9/site-packages/piqa/ssim.py", line 249, in forward
    assert_type(
  File "/users/PAS2490/marcusshen/miniconda3/envs/imae/lib/python3.9/site-packages/piqa/utils/__init__.py", line 91, in assert_type
    assert value_range[0] <= t.min(), f"Expected all values to be greater or equal to {value_range[0]}, but got {t.min().item()}."
AssertionError: Expected all values to be greater or equal to 0.0, but got nan.
[2024-08-23 12:04:48,788] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 569694) of binary: /users/PAS2490/marcusshen/miniconda3/envs/imae/bin/python
Traceback (most recent call last):
  File "/users/PAS2490/marcusshen/miniconda3/envs/imae/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/users/PAS2490/marcusshen/miniconda3/envs/imae/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/users/PAS2490/marcusshen/miniconda3/envs/imae/lib/python3.9/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/users/PAS2490/marcusshen/miniconda3/envs/imae/lib/python3.9/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/users/PAS2490/marcusshen/miniconda3/envs/imae/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/users/PAS2490/marcusshen/miniconda3/envs/imae/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
../program/main.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-08-23_12:04:48
  host      : a0019.ten.osc.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 569694)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Train end time: 2024-08-23_12:04:49
Train Time taken:  hours,  minutes and  seconds
